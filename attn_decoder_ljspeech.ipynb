{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "#import pandas as pd\n",
    "#from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "%aimport read_audio\n",
    "%aimport dataset\n",
    "%aimport melLM\n",
    "%aimport train_attn\n",
    "#%aimport main_mel_seq2seq\n",
    "\n",
    "\n",
    "from read_audio import read_pickles\n",
    "\n",
    "from dataset import Mel\n",
    "from dataset import MelDataset\n",
    "from dataset import make_grouping\n",
    "\n",
    "\n",
    "#from melLM import Encoder\n",
    "from melLM import EncoderCell\n",
    "from melLM import BahdanauAttnDecoderRNN\n",
    "#from melLM import NoAttnDecoder\n",
    "from melLM import Attn\n",
    "from melLM import Conv_FB_Highway\n",
    "#from main_mel_seq2seq import main\n",
    "%aimport melLM\n",
    "from melLM import get_encoder\n",
    "from melLM import get_decoder\n",
    "\n",
    "\n",
    "from melLM import get_conv_fb_highway \n",
    "\n",
    "\n",
    "#from train import train\n",
    "from train_attn import run_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.input_size = 80\n",
    "        self.num_layers = 2\n",
    "        self.stack_size = 2\n",
    "        self.r = 1\n",
    "        self.hidden_size = 600\n",
    "        self.batch_size = 60\n",
    "        self.seq_len_max = 100\n",
    "        self.num_epochs = 551\n",
    "        self.lr = 1e-4\n",
    "        self.restart_file=''\n",
    "        self.encoder_type='plain'\n",
    "        self.dump_mels = True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from main_mel_seq2seq import get_encoder, get_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mel(source,target):\n",
    "    import librosa\n",
    "    for i in range(len(source)):\n",
    "        source[i] = librosa.util.normalize(source[i],axis=1)\n",
    "        target[i] = librosa.util.normalize(target[i],axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "    return source,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_mel(source, target):\n",
    "    import numpy as np\n",
    "    \n",
    "    epsilon = 1e-4\n",
    "    \n",
    "    sum_source_vector = np.zeros((params.input_size))\n",
    "    sum_target_vector = np.zeros((params.input_size))\n",
    "    \n",
    "    print('source[0].shape', source[0].shape)\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        sum_source_vector += np.mean(source[i], axis = 1)\n",
    "        sum_target_vector += np.mean(target[i], axis = 1)\n",
    "        \n",
    "        \n",
    "    print('yes yes yes yes')\n",
    "    sum_source_vector /=len(source)\n",
    "    sum_target_vector /=len(source)\n",
    "\n",
    "        \n",
    "    sum_source_vector = np.expand_dims(sum_source_vector, axis=1)\n",
    "    sum_target_vector = np.expand_dims(sum_target_vector, axis=1)\n",
    "    #print('ssv.shape', sum_source_vector.shape)\n",
    "    #print('stv.shape', sum_target_vector.shape)\n",
    "    \n",
    "    #print('sum_source_vector', sum_source_vector)\n",
    "    \n",
    "        \n",
    "    for i in range(len(source)):\n",
    "        source[i] = (source[i] - sum_source_vector)/(sum_source_vector + epsilon)\n",
    "        target[i] = (target[i] - sum_target_vector)/(sum_target_vector + epsilon)\n",
    "     \n",
    "    \n",
    "    return source, target, sum_source_vector, sum_target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "#dir = '/mnt/large_hd/cmu_data'\n",
    "#dir = '/mnt/raid/cmu_arctic_data'\n",
    "#dir = '/mnt/raid/combined_data'\n",
    "#dir = '/mnt/raid/LJSpeech_mels'\n",
    "#dir = '/mnt/large_hd/audio_mels'\n",
    "#dir = '/mnt/raid/vcc_mels'\n",
    "#dir = '/mnt/large_hd/audio_mels'\n",
    "\n",
    "#dir = '/mnt/large_hd/LJSpeech-256-dumps'\n",
    "dir = './ljspeech/oct19'\n",
    "#dir = '/mnt/raid/working_data/nancy'\n",
    "#dir = '/mnt/raid/working_data/cmu_arctic/'\n",
    "#dir = '/mnt/raid/working_data/LJSpeech_16000'\n",
    "#dir = '/mnt/raid/working_data/LJSpeech_22050_400'\n",
    "\n",
    "\n",
    "#source_voices = ['SF1','SF2','SF3','SM1','SM2']\n",
    "#target_voices = ['TF1','TF2','TM1','TM2','TM3']\n",
    "\n",
    "source_voices = ['wavs']\n",
    "target_voices = ['wavs']\n",
    "\n",
    "#source_voices = ['clb']\n",
    "#target_voices = ['slt']\n",
    "\n",
    "#source_voices = ['wavs']\n",
    "#target_voices = ['wavs']\n",
    "\n",
    "\n",
    "for i in range(len(source_voices)):\n",
    "    source = read_pickles(dir,source_voices[i]) #dict \n",
    "    print('name', source['name'])\n",
    "    \n",
    "    if i>0:\n",
    "        sv += source['mels']\n",
    "    else:\n",
    "        sv = source['mels']\n",
    "        \n",
    "\n",
    "for i in range(len(target_voices)):\n",
    "    #tv.append(read_pickles(dir,target_voices[i]))\n",
    "    target = read_pickles(dir, target_voices[i])\n",
    "    print('name', target['name'])\n",
    "    \n",
    "    if i>0:\n",
    "        tv += target['mels']\n",
    "    else:\n",
    "        tv = target['mels']\n",
    "\n",
    "print('Creating groupings to class mels and associated assets')\n",
    "#print(sv[0]['name'])\n",
    "        \n",
    "#just do SF1, TF1 for now\n",
    "#SF1 = make_grouping(sv[0]['mels'])\n",
    "#TF1 = make_grouping(tv[0]['mels'])\n",
    "\n",
    "#SF1 = sv[0]['mels']\n",
    "#TF1 = tv[0]['mels']\n",
    "\n",
    "#for i in range()\n",
    "\n",
    "\n",
    "train_split = 0.9\n",
    "test_split = 0.1\n",
    "num_batches = len(sv)//params.batch_size\n",
    "#num_batches = 7000//params.batch_size\n",
    "data_size = params.batch_size*num_batches \n",
    "#print('sv.shape', len(sv), params.batch_size,data_size)\n",
    "\n",
    "print('Creating Dataset')\n",
    "#print('yes yes')\n",
    "\n",
    "#SF1,TF1 = normalize_mel(SF1,TF1)\n",
    "\n",
    "train_size = int(data_size * train_split)\n",
    "\n",
    "#sv, tv, mean_sv, mean_tv = get_normalized_mel(sv,tv)\n",
    "\n",
    "mel_dataset_train = MelDataset(sv[:train_size],tv[:train_size],params.stack_size)\n",
    "maxlen_source = mel_dataset_train.maxlen_source\n",
    "\n",
    "mel_dataset_test = MelDataset(sv[train_size:data_size],tv[train_size:data_size],params.stack_size,maxlen_source)\n",
    "\n",
    "\n",
    "#create train loader \n",
    "train_loader = DataLoader(mel_dataset_train, batch_size=params.batch_size,shuffle=True,num_workers=1)\n",
    "test_loader = DataLoader(mel_dataset_test, batch_size=params.batch_size,shuffle=True,num_workers=1)\n",
    "\n",
    "\n",
    "print('size of train loader', len(train_loader))\n",
    "print('size of test loader', len(test_loader))\n",
    "\n",
    "#print('yes yes')\n",
    "\n",
    "params = Params()\n",
    "\n",
    "encoder = get_encoder(params)\n",
    "#encoder = Encoder(params.input_size,params.hidden_size,params.batch_size, params.num_layers)\n",
    "#decoder = get_decoder(params)\n",
    "\n",
    "#encoder = EncoderCell(params.input_size,params.hidden_size)\n",
    "encoder = encoder.cuda()\n",
    "\n",
    "\n",
    "decoder = get_decoder(params)\n",
    "decoder = decoder.cuda()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('encoder', encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, [sample,seq_len] in enumerate(train_loader):\n",
    "    mask = sample['mask']\n",
    "    print('mask', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel(mel):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import librosa.display \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    #librosa.display.specshow(librosa.power_to_db(mel,ref=np.max),\n",
    "    #                 y_axis='mel', fmax=8000, x_axis='time')\n",
    "    librosa.display.specshow(mel,\n",
    "                     y_axis='mel', fmax=8000, x_axis='time')\n",
    "    #plt.colorbar(format='%+2.0f dB')\n",
    "    #plt.title('Mel spectrogram')\n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "    #plt.savefig('dumps2/mel_'+str(i)+'.png')\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,[sample,seq_len] in enumerate(train_loader):\n",
    "    src = sample['source']\n",
    "    tgt = sample['target']\n",
    "    mask = sample['mask']\n",
    "    print('src.shape',src[0].shape)\n",
    "    #plot_mel(src[0].numpy())\n",
    "    #plot_mel(tgt[0].numpy())\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = src[0].numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display \n",
    "plt.figure()\n",
    "'''librosa.display.specshow(librosa.power_to_db(s,ref=np.max),\n",
    "                     y_axis='mel', fmax=8000, x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig('dumps2/mel_'+str(i)+'.png')\n",
    "plt.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audio\n",
    "s = src[0].numpy()\n",
    "\n",
    "plot_mel(s)\n",
    "#print('mean_sv', mean_sv)\n",
    "print('sv[0]', sv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = src[0].shape[1]\n",
    "print(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_len = 208\n",
    "conv_fb_highway = get_conv_fb_highway(params,seq_len)\n",
    "conv_fb_highway = conv_fb_highway.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(),params.lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), params.lr)\n",
    "conv_fb_highway_optimizer = optim.Adam(conv_fb_highway.parameters(),params.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_trainer(train_loader, test_loader,params, encoder,decoder,conv_fb_highway,encoder_optimizer,decoder_optimizer,conv_fb_highway_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "80*208*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_attn import run_tester\n",
    "from test_attn import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tester(test_loader,params,encoder,decoder,conv_fb_highway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "190*600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(10,10)\n",
    "b = torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.expand_as(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((a,b),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(10,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.expand(16,10,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2,5)\n",
    "y1 = torch.ones(2)\n",
    "y2 = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.cat((y1,y2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.zeros(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(10,20,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = [80,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [256,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sizes[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim + sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[in_dim]+sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[in_dim]+sizes[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ByteTensor(4,4).zero_().byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0][:2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 4*torch.ones(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.masked_fill_(mask,-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = [ 0.2081,  0.4601,  0.7598,  0.9615,  0.1249, -1.3553, -2.1334,\n",
    "        -2.0015, -1.3928, -0.6678, -0.0965,  0.2664,  0.6829,  1.1478,\n",
    "         1.2630,  1.2874,  1.2073]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = np.asarray(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = torch.from_numpy(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,\n",
    "         1,  1,  1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.asarray(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.masked_fill(mask,-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Variable(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn.data.masked_fill(mask,-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = Variable(attn.data.masked_fill(mask,-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(10,5,1)\n",
    "y = torch.FloatTensor(10,5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones((80,20))\n",
    "y = np.zeros((80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y += np.sum(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(x, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.ones((4,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.ones((4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z-q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[1]\n",
    "y=[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
